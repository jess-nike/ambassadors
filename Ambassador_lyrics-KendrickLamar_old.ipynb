{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chemical-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "included-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine learning libraries for Text analysis\n",
    "import nltk  # machine learning with text\n",
    "from nltk import download as nltk_download\n",
    "from nltk.corpus import stopwords, wordnet  # List of common words\n",
    "from nltk.tokenize import word_tokenize  # Split text into significant forms\n",
    "from nltk.stem import WordNetLemmatizer  # Reduce words to their root form\n",
    "from nltk import pos_tag  # Tag words with parts of speech\n",
    "from collections import defaultdict  # Dictionaries that have a backup value\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Convert text to sparse matrices\n",
    "from textblob import TextBlob  # Sentiment analysis\n",
    "from gensim.models.ldamodel import LdaModel  # Topic extraction\n",
    "from gensim.models.phrases import Phrases  # ngrams\n",
    "from gensim import corpora  # Vectorization\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-testament",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Kendrick Lamar...\n",
      "\n",
      "Song 1: \"HUMBLE.\"\n",
      "Song 2: \"​m.A.A.d city\"\n"
     ]
    }
   ],
   "source": [
    "from lyricsgenius import Genius\n",
    "\n",
    "genius = Genius('JOSfSO0Cn0Y3avlw_ItRLdmwFj3s-36fjS-POUolMGFiWkUiE_zHXfQZVsOOqbxA')\n",
    "artist = genius.search_artist(\"Kendrick Lamar\", max_songs=200)\n",
    "kendrick_json = artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kendrick = pd.read_json('Lyrics_kendrickEilish.json', orient='index')\n",
    "#kendrick = pd.read_json(codecs.open('Lyrics_kendrickEilish.json','r','utf-8'))\n",
    "#df = json.loads('Lyrics_kendrickEilish.json').text\n",
    "#df = pd.DataFrame.from_dict('Lyrics_kendrickEilish.json', orient='index')\n",
    "with open('Lyrics_KendrickLamar.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "df = pd.DataFrame(data['songs'])\n",
    "kendrick_df = df[['full_title', 'artist', 'lyrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-phase",
   "metadata": {},
   "source": [
    "# Lyric Analysis\n",
    "\n",
    "## Cleaning the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics = kendrick_df.lyrics.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"(\\u2019)\", value=\"'\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"won’t\", value=\"will not\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"can’t\", value=\"can not\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"wanna\", value=\"want to\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"n't\", value=\" not\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"it's\", value=\"it is\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"i've\", value=\"i have\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"i'm\", value=\"i am\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=\"n' \", value=\"ng \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"[verse ..]\" and \"[chorus]\"\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=r\"\\[verse \\d\\]\", value=\"\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=r\"\\[chorus\\]\", value=\"\", regex=True)\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=r\"\\[bridge\\]\", value=\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=\" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=r\"\\[chorus\\]\", value=\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics = kendrick_df.lyrics.replace(to_replace=r\"\\W\", value=\" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-conviction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove common words from English lyrics \n",
    "\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.apply(word_tokenize)\n",
    "stop_words = stopwords.words(\"english\")\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.apply(lambda x: [y for y in x if y not in stop_words\n",
    "                                                              and len(y) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendrick_df.lyrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Dictionary to convert between part-of-speech tags and the ones the lemmatizer understands\n",
    "\n",
    "tag_dict = defaultdict(lambda : wordnet.NOUN)\n",
    "tag_dict['J'] = wordnet.ADJ\n",
    "tag_dict['V'] = wordnet.VERB\n",
    "tag_dict['R'] = wordnet.ADV\n",
    "\n",
    "# function to lemmatize a sentence\n",
    "\n",
    "def get_lemma(word):\n",
    "    \"\"\"Gets the POS tag for a word, and then returns the lemmatized form of the word\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0]\n",
    "    tag = tag_dict[tag]\n",
    "    \n",
    "    return lemma.lemmatize(word, tag)\n",
    "\n",
    "# Perform the lemmatization\n",
    "kendrick_df.lyrics = kendrick_df.lyrics.apply(lambda x: [get_lemma(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of words and their frequency (corpus)\n",
    "from gensim import corpora\n",
    "pyLDAvis.enable_notebook()\n",
    "dictionary = corpora.Dictionary(kendrick_df.lyrics )\n",
    "corpus = [dictionary.doc2bow(text) for text in kendrick_df.lyrics ]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 3\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model3.gensim')\n",
    "topics = ldamodel.print_topics(num_words=6)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-certificate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-objective",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3.9",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
